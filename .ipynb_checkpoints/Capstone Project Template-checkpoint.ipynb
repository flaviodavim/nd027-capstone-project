{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "This project was made to get the immigration data and make all changes needed to clean the data and get the main information where we'd make some analysis and undestand some pattern.\n",
    "\n",
    "The main objective is get only the information that can bring us some important idea about:\n",
    "- How they enter the country (the vehicle used, the visa type)\n",
    "- Where they come from and where they go\n",
    "- When they come and how the spend in the country\n",
    "\n",
    "All this information can be used to make more accurate decisions about how to invest the states money. For example, if a state receive many immigrants from airplanes, they can invest in better airports. Other example is one state which is receiving many people to perform a specific job, could be an option invest in a better education in that segment.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from pyspark.sql.functions import udf, expr, pandas_udf, year, month, dayofmonth\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, DateType, TimestampType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "For this project, we will use the US immigration data from the year 2016. These data are provided by the US National Tourism and Trade Office through its website and they offer details of these immigrants such as the place of immigration, the date of arrival, the type of immigration visa, among other information. \n",
    "\n",
    "These datasets will be restructured to contain less information because we want to understand only the types of immigrants that are arriving in the country using their type of visa and the place they are immigrating to. \n",
    "\n",
    "These information are sufficient to have a good idea about the immigration profile in each state and can be useful to government officials to improve tourism or even education policies based on these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2027561</td>\n",
       "      <td>4084316.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>HHW</td>\n",
       "      <td>20566.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>HI</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>07202016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JL</td>\n",
       "      <td>5.658267e+10</td>\n",
       "      <td>00782</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2171295</td>\n",
       "      <td>4422636.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>582.0</td>\n",
       "      <td>MCA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10222016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>*GA</td>\n",
       "      <td>9.436200e+10</td>\n",
       "      <td>XBLNG</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>589494</td>\n",
       "      <td>1195600.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>OGG</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>FL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>07052016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LH</td>\n",
       "      <td>5.578047e+10</td>\n",
       "      <td>00464</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2631158</td>\n",
       "      <td>5291768.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20572.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>10272016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QR</td>\n",
       "      <td>9.478970e+10</td>\n",
       "      <td>00739</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3032257</td>\n",
       "      <td>985523.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>CHM</td>\n",
       "      <td>20550.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NY</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>07042016</td>\n",
       "      <td>F</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.232257e+10</td>\n",
       "      <td>LAND</td>\n",
       "      <td>WT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  \\\n",
       "0     2027561  4084316.0  2016.0     4.0   209.0   209.0     HHW  20566.0   \n",
       "1     2171295  4422636.0  2016.0     4.0   582.0   582.0     MCA  20567.0   \n",
       "2      589494  1195600.0  2016.0     4.0   148.0   112.0     OGG  20551.0   \n",
       "3     2631158  5291768.0  2016.0     4.0   297.0   297.0     LOS  20572.0   \n",
       "4     3032257   985523.0  2016.0     4.0   111.0   111.0     CHM  20550.0   \n",
       "\n",
       "   i94mode i94addr    ...     entdepu  matflag  biryear   dtaddto  gender  \\\n",
       "0      1.0      HI    ...         NaN        M   1955.0  07202016       F   \n",
       "1      1.0      TX    ...         NaN        M   1990.0  10222016       M   \n",
       "2      1.0      FL    ...         NaN        M   1940.0  07052016       M   \n",
       "3      1.0      CA    ...         NaN        M   1991.0  10272016       M   \n",
       "4      3.0      NY    ...         NaN        M   1997.0  07042016       F   \n",
       "\n",
       "  insnum airline        admnum  fltno  visatype  \n",
       "0    NaN      JL  5.658267e+10  00782        WT  \n",
       "1    NaN     *GA  9.436200e+10  XBLNG        B2  \n",
       "2    NaN      LH  5.578047e+10  00464        WT  \n",
       "3    NaN      QR  9.478970e+10  00739        B2  \n",
       "4    NaN     NaN  4.232257e+10   LAND        WT  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the data here\n",
    "df = pd.read_csv('immigration_data_sample.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\t\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[cicid: double, i94yr: double, i94mon: double, i94cit: double, i94res: double, i94port: string, arrdate: double, i94mode: double, i94addr: string, depdate: double, i94bir: double, i94visa: double, count: double, dtadfile: string, visapost: string, occup: string, entdepa: string, entdepd: string, entdepu: string, matflag: string, biryear: double, dtaddto: string, gender: string, insnum: string, airline: string, admnum: double, fltno: string, visatype: string]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "In the analyzes we want to perform, it is more important to work with the known data than try to treat all the data, so we will do the following steps:\n",
    "\n",
    "- Remove the lines that do not have a visa type value;\n",
    "- Remove the lines that do not have the information about the state that received the immigrant;\n",
    "- Remove the lines that have distinct values for the i94cit and i94res columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_spark = df_spark.filter(\"i94cit == i94res and i94addr != '' and visatype != '' and arrdate is not null and depdate is not null\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[cicid: double, i94yr: double, i94mon: double, i94cit: double, i94res: double, i94port: string, arrdate: double, i94mode: double, i94addr: string, depdate: double, i94bir: double, i94visa: double, count: double, dtadfile: string, visapost: string, occup: string, entdepa: string, entdepd: string, entdepu: string, matflag: string, biryear: double, dtaddto: string, gender: string, insnum: string, airline: string, admnum: double, fltno: string, visatype: string]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df_spark.withColumn('immigration_id', expr('cast(cicid as int)')).withColumn('origin_id', expr('cast(i94cit as int)')).withColumn('visa_id', expr('cast(i94visa as int)')).withColumn('mode_id', expr('cast(i94mode as int)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_timestamp_from_sas = udf(lambda sas: datetime.datetime(1960, 1, 1) + datetime.timedelta(days=int(sas)), TimestampType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.withColumn('arrival_date', get_timestamp_from_sas(df.arrdate)).withColumn('departure_date', get_timestamp_from_sas(df.depdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[cicid: double, i94yr: double, i94mon: double, i94cit: double, i94res: double, i94port: string, arrdate: double, i94mode: double, i94addr: string, depdate: double, i94bir: double, i94visa: double, count: double, dtadfile: string, visapost: string, occup: string, entdepa: string, entdepd: string, entdepu: string, matflag: string, biryear: double, dtaddto: string, gender: string, insnum: string, airline: string, admnum: double, fltno: string, visatype: string, immigration_id: int, origin_id: int, visa_id: int, mode_id: int, arrival_date: timestamp, departure_date: timestamp]>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = df.selectExpr('immigration_id', 'origin_id', 'i94addr as destination', \n",
    "                                                 'arrival_date', 'departure_date', 'dayofmonth(arrival_date) as day', 'month(arrival_date) as month', 'year(arrival_date) as year',\n",
    "                                                 'mode_id', 'visa_id', 'visatype as visa_type_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+-------------------+-------------------+---+-----+----+-------+-------+------------+\n",
      "|immigration_id|origin_id|destination|       arrival_date|     departure_date|day|month|year|mode_id|visa_id|visa_type_id|\n",
      "+--------------+---------+-----------+-------------------+-------------------+---+-----+----+-------+-------+------------+\n",
      "|            15|      101|         MI|2016-04-01 00:00:00|2016-08-25 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            16|      101|         MA|2016-04-01 00:00:00|2016-04-23 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            17|      101|         MA|2016-04-01 00:00:00|2016-04-23 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            18|      101|         MI|2016-04-01 00:00:00|2016-04-11 00:00:00|  1|    4|2016|      1|      1|          B1|\n",
      "|            19|      101|         NJ|2016-04-01 00:00:00|2016-04-14 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            20|      101|         NJ|2016-04-01 00:00:00|2016-04-14 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            21|      101|         NY|2016-04-01 00:00:00|2016-04-09 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            22|      101|         NY|2016-04-01 00:00:00|2016-04-18 00:00:00|  1|    4|2016|      1|      1|          B1|\n",
      "|            23|      101|         NY|2016-04-01 00:00:00|2016-08-05 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            24|      101|         MO|2016-04-01 00:00:00|2016-04-10 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            27|      101|         MA|2016-04-01 00:00:00|2016-04-05 00:00:00|  1|    4|2016|      1|      1|          B1|\n",
      "|            28|      101|         MA|2016-04-01 00:00:00|2016-04-05 00:00:00|  1|    4|2016|      1|      1|          B1|\n",
      "|            29|      101|         MA|2016-04-01 00:00:00|2016-04-17 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            30|      101|         NJ|2016-04-01 00:00:00|2016-05-04 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            31|      101|         NY|2016-04-01 00:00:00|2016-06-06 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            33|      101|         TX|2016-04-01 00:00:00|2016-04-10 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            36|      101|         NJ|2016-04-01 00:00:00|2016-04-17 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            37|      101|         NJ|2016-04-01 00:00:00|2016-04-23 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            38|      101|         NY|2016-04-01 00:00:00|2016-05-01 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "|            39|      101|         FL|2016-04-01 00:00:00|2016-04-30 00:00:00|  1|    4|2016|      1|      2|          B2|\n",
      "+--------------+---------+-----------+-------------------+-------------------+---+-----+----+-------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "A star schema that would be used for this data set was idealized, allowing the useful data for the analyzes and for the clusters to be gathered in the main table, while the other tables bring more descriptive information that will be important later to better detail the results.\n",
    "\n",
    "To format this data model would not be necessary too many steps, because the immigration data set already contains the necessary information for the fact table, so it is only needed to remove a few columns and modify the columns containing dates to format them correctly.\n",
    "\n",
    "As for dimension tables, they will be created using information that describes the values of the dataset columns and that are found either on government websites or in the dataset description document.\n",
    "\n",
    "The image below represents the schema choosen to our database:\n",
    "![Star Schema](images/StarSchema.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    file = '../../data/18-83510-I94-Data-2016/{}'.format(filename)\n",
    "    return spark.read.format('com.github.saurfang.sas.spark').load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    return df.filter(\"i94cit == i94res and i94addr != '' and visatype != '' and arrdate is not null and depdate is not null\").dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "get_timestamp_from_sas = udf(lambda sas: datetime.datetime(1960, 1, 1) + datetime.timedelta(days=int(sas)), TimestampType())\n",
    "\n",
    "def get_column_dates_from_sas_to_timestamp(df):\n",
    "    return df.withColumn('arrival_date', get_timestamp_from_sas(df.arrdate)).withColumn('departure_date', get_timestamp_from_sas(df.depdate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_ids_columns(df):\n",
    "    return df.withColumn('immigration_id', expr('cast(cicid as int)')).withColumn('origin_id', expr('cast(i94cit as int)')).withColumn('visa_id', expr('cast(i94visa as int)')).withColumn('mode_id', expr('cast(i94mode as int)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def select_columns(df):\n",
    "    return df.selectExpr('immigration_id', 'origin_id', 'i94addr as destination', 'arrival_date', 'departure_date', 'mode_id', 'visa_id', 'visatype as visa_type_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def etl(files):\n",
    "    for num, name in enumerate(files, start=1):\n",
    "        df_immigrations = read_data(name)\n",
    "\n",
    "        df_immigrations = clean(df_immigrations)\n",
    "        df_immigrations = get_ids_columns(df_immigrations)\n",
    "        df_immigrations = get_column_dates_from_sas_to_timestamp(df_immigrations)\n",
    "        df_immigrations = select_columns(df_immigrations)\n",
    "\n",
    "        df_immigrations.write.partitionBy('visa_type_id').parquet('parquet_data/{}/'.format(num), mode='overwrite')\n",
    "\n",
    "        print(\"File {}: {}.\".format(num, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1: i94_jan16_sub.sas7bdat.\n",
      "File 2: i94_feb16_sub.sas7bdat.\n",
      "File 3: i94_mar16_sub.sas7bdat.\n",
      "File 4: i94_apr16_sub.sas7bdat.\n",
      "File 5: i94_may16_sub.sas7bdat.\n",
      "File 6: i94_jun16_sub.sas7bdat.\n",
      "File 7: i94_jul16_sub.sas7bdat.\n",
      "File 8: i94_aug16_sub.sas7bdat.\n",
      "File 9: i94_sep16_sub.sas7bdat.\n",
      "File 10: i94_oct16_sub.sas7bdat.\n",
      "File 11: i94_nov16_sub.sas7bdat.\n",
      "File 12: i94_dec16_sub.sas7bdat.\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    'i94_jan16_sub.sas7bdat',\n",
    "    'i94_feb16_sub.sas7bdat',\n",
    "    'i94_mar16_sub.sas7bdat',\n",
    "    'i94_apr16_sub.sas7bdat',\n",
    "    'i94_may16_sub.sas7bdat',\n",
    "    'i94_jun16_sub.sas7bdat',\n",
    "    'i94_jul16_sub.sas7bdat',\n",
    "    'i94_aug16_sub.sas7bdat',\n",
    "    'i94_sep16_sub.sas7bdat',\n",
    "    'i94_oct16_sub.sas7bdat',\n",
    "    'i94_nov16_sub.sas7bdat',\n",
    "    'i94_dec16_sub.sas7bdat'\n",
    "]\n",
    "\n",
    "etl(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The data quality used in this project is only check if the ids aren't null or empty. Here whe are get only the january value to make fastier the process, mas what is made here can be used in a Airflow step using a database as Redshift.\n",
    "\n",
    "The main objective is the queries return a empty list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+-------------------+-------------------+---+-----+----+-------+-------+------------+\n",
      "|immigration_id|origin_id|destination|       arrival_date|     departure_date|day|month|year|mode_id|visa_id|visa_type_id|\n",
      "+--------------+---------+-----------+-------------------+-------------------+---+-----+----+-------+-------+------------+\n",
      "|          1153|      107|         IL|2016-01-16 00:00:00|2016-01-30 00:00:00| 16|    1|2016|      1|      2|          B2|\n",
      "|         16124|      131|         NY|2016-01-08 00:00:00|2016-01-12 00:00:00|  8|    1|2016|      1|      2|          B2|\n",
      "|         26940|      165|         CA|2016-01-01 00:00:00|2016-03-21 00:00:00|  1|    1|2016|      1|      2|          B2|\n",
      "|         28627|      209|         GU|2016-01-06 00:00:00|2016-01-09 00:00:00|  6|    1|2016|      1|      2|          B2|\n",
      "|         46913|      245|         IL|2016-01-08 00:00:00|2016-01-31 00:00:00|  8|    1|2016|      1|      2|          B2|\n",
      "|         47174|      245|         OH|2016-01-14 00:00:00|2016-04-14 00:00:00| 14|    1|2016|      1|      2|          B2|\n",
      "|         47442|      245|         WI|2016-01-21 00:00:00|2016-03-18 00:00:00| 21|    1|2016|      1|      2|          B2|\n",
      "|         47629|      245|         CA|2016-01-29 00:00:00|2016-02-15 00:00:00| 29|    1|2016|      1|      2|          B2|\n",
      "|         47714|      245|         TX|2016-01-22 00:00:00|2016-02-07 00:00:00| 22|    1|2016|      1|      2|          B2|\n",
      "|         52709|      245|         CA|2016-01-23 00:00:00|2016-02-12 00:00:00| 23|    1|2016|      1|      2|          B2|\n",
      "|         62044|      245|         CA|2016-01-17 00:00:00|2016-01-22 00:00:00| 17|    1|2016|      1|      2|          B2|\n",
      "|         62872|      250|         CA|2016-01-17 00:00:00|2016-01-26 00:00:00| 17|    1|2016|      1|      2|          B2|\n",
      "|         63171|      251|         NV|2016-01-20 00:00:00|2016-02-09 00:00:00| 20|    1|2016|      1|      2|          B2|\n",
      "|         63904|      253|         II|2016-01-23 00:00:00|2016-03-27 00:00:00| 23|    1|2016|      1|      2|          B2|\n",
      "|         70114|      258|         IL|2016-01-14 00:00:00|2016-02-09 00:00:00| 14|    1|2016|      1|      2|          B2|\n",
      "|         70706|      258|         TX|2016-01-21 00:00:00|2016-02-15 00:00:00| 21|    1|2016|      1|      2|          B2|\n",
      "|         71609|      258|         NJ|2016-01-06 00:00:00|2016-01-07 00:00:00|  6|    1|2016|      1|      2|          B2|\n",
      "|         78175|      261|         FL|2016-01-11 00:00:00|2016-01-21 00:00:00| 11|    1|2016|      1|      2|          B2|\n",
      "|         78447|      261|         MD|2016-01-04 00:00:00|2016-01-18 00:00:00|  4|    1|2016|      1|      2|          B2|\n",
      "|         82564|      263|         NV|2016-01-18 00:00:00|2016-01-23 00:00:00| 18|    1|2016|      1|      2|          B2|\n",
      "+--------------+---------+-----------+-------------------+-------------------+---+-----+----+-------+-------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "january_df = spark.read.parquet('parquet_data/1/')\n",
    "january_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "january_df.createOrReplaceTempView('immigrations_january')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "|immigration_id|origin_id|destination|arrival_date|departure_date|day|month|year|mode_id|visa_id|visa_type_id|\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM immigrations_january WHERE (immigration_id IS NULL OR immigration_id = \"\")').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "|immigration_id|origin_id|destination|arrival_date|departure_date|day|month|year|mode_id|visa_id|visa_type_id|\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM immigrations_january WHERE (origin_id IS NULL OR origin_id = \"\")').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "|immigration_id|origin_id|destination|arrival_date|departure_date|day|month|year|mode_id|visa_id|visa_type_id|\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM immigrations_january WHERE (mode_id IS NULL OR mode_id = \"\")').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "|immigration_id|origin_id|destination|arrival_date|departure_date|day|month|year|mode_id|visa_id|visa_type_id|\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM immigrations_january WHERE (visa_id IS NULL OR visa_id = \"\")').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "|immigration_id|origin_id|destination|arrival_date|departure_date|day|month|year|mode_id|visa_id|visa_type_id|\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "+--------------+---------+-----------+------------+--------------+---+-----+----+-------+-------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('SELECT * FROM immigrations_january WHERE (visa_type_id IS NULL OR visa_type_id = \"\")').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "This dictionary is in `data_model.SAS` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "The purpose of this structure is to perform better grouping, therefore with the data in this format I can make the groups according to the type of visa, the mode of arrival or even by the state of arrival. \n",
    " \n",
    "These possibilities allow the profile of immigrants arriving in each region to be well explored, in this way the objective is to better understand these profiles to improve public policies according to the needs of each state. For example, when a state brings few tourists, it may be interesting to see if there is room for more tourism in that region. Another option is to check if a region receives many immigrants who enter the country to work, this may indicate that there are areas in the country that can be better supported.\n",
    " \n",
    "The Spark is already used in the project, but the Airflow can be an important addition to allow regulation of tasks according to a scheduler and make the process more agile and automatic without losing control of the steps.\n",
    "\n",
    "- If the data was increased by 100x.\n",
    "\n",
    "A good alternative, in case the data increased a lot, would be to process the data in smaller chunks that can run in parallel to make the process faster and more efficient.\n",
    "\n",
    "- If the pipelines were run on a daily basis by 7am.\n",
    "\n",
    "The Airflow easily allows you to add this option to define a scheduler that can allow the data to search every day if there is new data to process.\n",
    "\n",
    "- If the database needed to be accessed by 100+ people.\n",
    "\n",
    "The idea is for these data to be available in a database, so one of the steps defined in the Airflow would be to insert the data into the database to become available. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
